{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid crashing when importing pytroch.nn deep learning\n",
    "\n",
    "# a way to make pytorch not crashing the python kernel in jupyter notebook\n",
    "# probally not have to do this in the newest version of cuda.\n",
    "\n",
    "# import os\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- HOW TO MAKE PYTORCH USE GPU --------------------------\n",
    "\n",
    "# at beginning of the script\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ...\n",
    "\n",
    "# then whenever you get a new Tensor or Module\n",
    "# this won't copy if they are already on the desired device\n",
    "# input = data.to(device)\n",
    "# model = MyModule(...).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4]])\n",
      " \n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      " \n",
      "tensor([[1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "matrix_a = [\n",
    "    [1,2,3,4]\n",
    "]\n",
    "\n",
    "# create a vector (torch vector) \n",
    "tV = torch.tensor(matrix_a)\n",
    "print(tV), print(' ')\n",
    "\n",
    "# get the transpose form\n",
    "print(tV.T), print(' ')\n",
    "\n",
    "# get the transpose form of the tranposed\n",
    "tVT = tV.T\n",
    "print(tVT.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      " \n",
      "tensor([[1, 5],\n",
      "        [2, 6],\n",
      "        [3, 7],\n",
      "        [4, 8]])\n",
      " \n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a matrix (torch matrix)\n",
    "\n",
    "matrix_a = [\n",
    "    [1,2,3,4],\n",
    "    [5,6,7,8]\n",
    "]\n",
    "\n",
    "# create a matrix (torch matrix)\n",
    "tM = torch.tensor(matrix_a)\n",
    "print(tM), print(' ')\n",
    "\n",
    "# get the transpose form\n",
    "print(tM.T), print(' ')\n",
    "\n",
    "# get the transpose form of the transposed\n",
    "tMT = tM.T\n",
    "print(tMT.T), print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of tV <class 'torch.Tensor'>\n",
      "type of tM <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# exampine data types\n",
    "\n",
    "print(f'type of tV {type(tV)}')\n",
    "print(f'type of tM {type(tM)}')\n",
    "\n",
    "# in pytorch: all scaler, array, vector, matrix, tensor are seen as \"tensor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random matrices\n",
    "\n",
    "A = torch.randn(3, 4)\n",
    "B = torch.randn(4, 5)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "C1 = np.random.randn(4, 7) # numpy matrix\n",
    "C2 = torch.tensor(C1, dtype=torch.float) # convert C1 numpy matrix into a pytorch tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0600, -1.0700,  1.8700,  2.9200, -1.3100, -0.6300, -1.2000],\n",
      "        [-0.5300, -1.8200, -0.2700, -0.1600, -0.8900, -0.9000,  1.5400],\n",
      "        [-2.1800,  0.2500,  0.7300, -0.5200,  1.2900,  2.0700, -0.7600]])\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(np.round(A@B, 2)), print(' ')\n",
    "# print(np.round(A@C1, 2)), print(' ')\n",
    "print(np.round(A@C2, 2)), print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min, max: -3, 40 \n",
      "min, max indices: 3,1 \n"
     ]
    }
   ],
   "source": [
    "# argmin, argmax\n",
    "\n",
    "v = torch.tensor([1,40, 2, -3])\n",
    "\n",
    "minval = torch.min(v)\n",
    "maxval = torch.max(v)\n",
    "\n",
    "print('Min, max: %g, %g ' %(minval, maxval))\n",
    "\n",
    "minidx = torch.argmin(v)\n",
    "maxidx = torch.argmax(v)\n",
    "\n",
    "print('min, max indices: %g,%g ' %(minidx, maxidx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "# now for the mmatrix\n",
    "\n",
    "M = torch.tensor([\n",
    "    [20 ,1, 10],\n",
    "    [0,8, 5]\n",
    "])\n",
    "\n",
    "min1 = torch.min(M)\n",
    "min2 = torch.min(M, axis = 0)\n",
    "min3 = torch.min(M, axis = 1)\n",
    "\n",
    "min1idx = torch.argmin(M)\n",
    "print(min1)\n",
    "print(min1idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.min(\n",
      "values=tensor([0, 1, 5]),\n",
      "indices=tensor([1, 0, 1]))\n",
      "tensor([0, 1, 5])\n",
      "tensor([1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "print(min2)\n",
    "print(min2.values)\n",
    "print(min2.indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2012, 0.7507, 0.0372, 1.4131, 0.6942])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch only use GLOBAL RANDOM SEED\n",
    "\n",
    "torch.randn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4135,  0.2336,  0.0340,  0.3499, -0.0145])\n",
      "[ 1.07561582 -1.35337436 -0.39129284  1.070874    1.18375495]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(17)\n",
    "print(torch.randn(5)) # the first randomcall from the starting point \"seed\" will always be the same\n",
    "\n",
    "# torch seed doesn't spread to numpy\n",
    "print(np.random.randn(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mywork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6391003d09935bdb03bcdc37a632cab92abcffb3a1dcbdeb9ce774a80334b563"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
